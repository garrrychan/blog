{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Life is like a box of chocolates\n",
    "Date: 2019-04-19 12:00\n",
    "Topic: Classification and Regression Trees\n",
    "Slug: chocolate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you have a sweet tooth, a guilty pleasure, or something that you eat to make you feel _happy_? Given some attributes of a snack, can I classify your favourite snack as a chocolate, or not chocolate (i.e. candy)? \n",
    "\n",
    "For example, if you told me that your favourite snack contains peanuts, and is not in a bar shape, my model should guess that this is chocolate (Reese Pieces)!\n",
    "\n",
    "This is a classification problem, so let's spin up decision trees and sprinkle in some ensemble methods\n",
    "(bagging & boosting) to improve prediction performance, and add a kick of flavour. This is a fun exercise to explore a variety of algorithms!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is from [The Ultimate Halloween Candy Power Ranking](https://github.com/fivethirtyeight/data/tree/master/candy-power-ranking).\n",
    "\n",
    "`candy-data.csv` includes attributes for each snack. For binary variables, 1 means yes, 0 means no.\n",
    "\n",
    "The data contains the following fields:\n",
    "\n",
    "<table class=\"table table-striped table-bordered\">\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Feature</th>\n",
    "<th>Description</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>chocolate</td>\n",
    "<td>Does it contain chocolate?</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>fruity</td>\n",
    "<td>Is it fruit flavored?</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>caramel</td>\n",
    "<td>Is there caramel in the candy?</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>peanutalmondy</td>\n",
    "<td>Does it contain peanuts, peanut butter or almonds?</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>nougat</td>\n",
    "<td>Does it contain nougat?</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>crispedricewafer</td>\n",
    "<td>Does it contain crisped rice, wafers, or a cookie component?</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>hard</td>\n",
    "<td>Is it a hard candy?</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>bar</td>\n",
    "<td>Is it a candy bar?</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>pluribus</td>\n",
    "<td>Is it one of many candies in a bag or box?</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>sugarpercent</td>\n",
    "<td>The percentile of sugar it falls under within the data set.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>pricepercent</td>\n",
    "<td>The unit price percentile compared to the rest of the set.</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plotting & viz\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.style.use('fivethirtyeight')\n",
    "import altair as alt \n",
    "alt.renderers.enable('notebook')\n",
    "from IPython.display import HTML\n",
    "\n",
    "# tree visualization\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "\n",
    "# supervised learning - modelling\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import catboost as cb\n",
    "from catboost import cv, CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "# unsupervised learning\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# model selection and evaluation\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, make_scorer\n",
    "\n",
    "# ensemble methods\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "\n",
    "# support warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/candy_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe table table-responsive table-striped table-bordered\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>competitorname</th>\n",
       "      <th>chocolate</th>\n",
       "      <th>fruity</th>\n",
       "      <th>caramel</th>\n",
       "      <th>peanutyalmondy</th>\n",
       "      <th>nougat</th>\n",
       "      <th>crispedricewafer</th>\n",
       "      <th>hard</th>\n",
       "      <th>bar</th>\n",
       "      <th>pluribus</th>\n",
       "      <th>sugarpercent</th>\n",
       "      <th>pricepercent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reeses Peanut Butter cup</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reeses Miniatures</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Twix</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kit Kat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Snickers</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove fake candies, One Dime, One Quarter\n",
    "df[(df.competitorname == \"One dime\") | (df.competitorname == \"One quarter\")] #index 47,77\n",
    "df = df.drop([47,77]).reset_index()\n",
    "df = df.drop(['index','winpercent'], 1) # drop win_%, focus on the snack attributes\n",
    "# great, now we have 83 observations to practice models on\n",
    "HTML(df.head().to_html(classes=\"table table-responsive table-striped table-bordered\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    46\n",
       "1    37\n",
       "Name: chocolate, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.chocolate.value_counts()\n",
    "# we have a pretty balanced class, between signal (#37 chocolates) and noise, and no missing values\n",
    "# great, no imbalanced classes procedure, or imputation required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target\n",
    "y = df[\"chocolate\"]\n",
    "\n",
    "# design matrix\n",
    "X = df.loc[:, 'fruity':'pricepercent']\n",
    "\n",
    "# train, test, split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5542168674698795"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline\n",
    "1 - y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's establish a 'naive model'. If we predicted everything as 100% chocolate, then we would be 55% accurate. This is our bench accuracy to beat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Trees 🌲"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate \n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit \n",
    "tree_model.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seeing is believing\n",
    "While trees are non parametric, one key benefit of decisions trees is that it's simple and interpretable with printouts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(\n",
    "    tree_model, \n",
    "    out_file=None, \n",
    "    feature_names=X.columns,  \n",
    "    class_names=[\"chocolate\",\"candy\"] #1 -> chocolate, 0 -> candy\n",
    ")\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "# Image(graph.create_png())\n",
    "# graph.write_svg(\"candytree.svg\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/candytree.svg\" alt=\"candytree\" class=\"img-responsive\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the tree is split on fruit flavour. If it's fruity, then it's probably not chocolate. Makes sense. \n",
    "\n",
    "And, if the snack is singular (i.e. 'pluribus'), contains peanuts, is high in sugar, and has nougats, then it's probably chocolate.\n",
    "\n",
    "\n",
    "--- \n",
    "\n",
    "* By default, the tree is split at each node based on Gini impurity. Gini is a measure of variance across the K classes; the smaller the Gini index, the better.\n",
    "\n",
    "\n",
    "* Remember, for a binary class, gini = 0 is a 'pure' split representing perfect equality, whereas gini = 0.5 is not pure.\n",
    "\n",
    "\n",
    "* You may see some splits where the nodes are both predicted to be chocolate. Well, why is a split event performed? Well, the split occurred because it increased node purity. That is the left split has 2/2 observations with a response value of chocolate, where as the right split is 1/2. If we have a new observation that belongs to the region in the left leaf, we can be sure its response value is chocolate, in contrast, if it goes into the right leaf, than it is probably yes, but we are much less certain.\n",
    "\n",
    "Now, let's use our model to predict if Reese's and Fuzzy Peaches are chocolate or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.iloc[0:1,:].to_dict(orient=\"list\")\n",
    "\n",
    "reeses = {'fruity': [0],\n",
    " 'caramel': [0],\n",
    " 'peanutyalmondy': [1],\n",
    " 'nougat': [0],\n",
    " 'crispedricewafer': [0],\n",
    " 'hard': [0],\n",
    " 'bar': [0],\n",
    " 'pluribus': [0],\n",
    " 'sugarpercent': [0.72000003],\n",
    " 'pricepercent': [0.65100002]}\n",
    "\n",
    "# new observation \n",
    "fuzzy_peach = {'fruity': [1],\n",
    " 'caramel': [0],\n",
    " 'peanutyalmondy': [0],\n",
    " 'nougat': [0],\n",
    " 'crispedricewafer': [0],\n",
    " 'hard': [0],\n",
    " 'bar': [0],\n",
    " 'pluribus': [0],\n",
    " 'sugarpercent': [0.75],\n",
    " 'pricepercent': [0.5]}\n",
    "\n",
    "reeses = pd.DataFrame(reeses)\n",
    "fuzzy_peach = pd.DataFrame(fuzzy_peach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " It's chocolate! [1]\n",
      " It's candy! [0]\n"
     ]
    }
   ],
   "source": [
    "print(f' It\\'s chocolate! {tree_model.predict(reeses)}')\n",
    "print(f' It\\'s candy! {tree_model.predict(fuzzy_peach)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tree_model train accuracy: 0.7931235431235432\n",
      " tree_model test accuracy: 0.7366666666666667\n"
     ]
    }
   ],
   "source": [
    "# Score: By default, cross_val_score calculates accuracy for trees\n",
    "print(f' tree_model train accuracy: {cross_val_score(tree_model, X_train, y_train, cv=5, scoring=make_scorer(accuracy_score)).mean()}')\n",
    "print(f' tree_model test accuracy: {cross_val_score(tree_model, X_test, y_test, cv=5).mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vanilla tree performs okay, as it's able to classify 74% of our test observations correctly, but there is some overfitting. \n",
    "\n",
    "It is significantly better than a naive model, so it is picking up signal. This is our new benchmark to beat. By applying bagging, let's see if we can cut down the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging\n",
    "\n",
    "Bagging stands for bootstrap aggregating. \n",
    "\n",
    "By definition, it's an averaging method and the idea is to build several bootstrapped estimators (i.e. trees) independently and then to average their predictions. The combined estimator is usually better than any of the single base estimator because its variance should be reduced.\n",
    "\n",
    "Usually, bagging mitigates overfitting by exposing different trees to different sub-samples of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bagged decision tree train accuracy 0.8367132867132867\n",
      " bagged decision tree test accuracy 0.7366666666666667\n"
     ]
    }
   ],
   "source": [
    "# Set of bagged decision trees\n",
    "\n",
    "# Instantiate\n",
    "bag = BaggingClassifier(n_estimators=100, max_samples=1.0, random_state = 42)\n",
    "# 'n_estimators=10', -> 10 trees in the ensemble to be averaged\n",
    "# 'max_samples=1.0', -> 1 samples to draw from X to train each tree\n",
    "\n",
    "# Fit\n",
    "bag.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "print(f' bagged decision tree train accuracy {cross_val_score(bag, X_train, y_train, cv=5).mean()}')\n",
    "print(f' bagged decision tree test accuracy {cross_val_score(bag, X_test, y_test, cv=5).mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we increased the `n_estimators`, the test accuracy improved, but it's capped at about 74%. This did not improve over our vanilla tree on the test set. Perhaps, we are still averaging highly correlated trees, therefore we are not enjoying the benefits of bagging.\n",
    "\n",
    "Suppose that there is one very strong predictor, along with a number of other moderately strong predictors. Then in the collection of bagged trees, most or all of the trees will use this strong predictor in the top split (i.e. fruity). Consequently, all of the bagged trees will look quite similar to each other. \n",
    "\n",
    "Hence, the predictions from the bagged trees will be highly correlated -> averaging many highly correlated quantities does not lead to as large of a reduction in variance -> bagging will not lead to a substantial reduction in variance over a single tree in this setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Random Forest 🌳🌳🌳\n",
    "Let's not be so greedy and gluttonous.\n",
    "\n",
    "Vanilla decisions trees and bagging uses a top-down, greedy approach. It is greedy because at each step of the tree-building process, the best split is made at that particular step, rather than looking ahead and picking a split that will lead to a better tree in some future step.\n",
    "\n",
    "Random forests provide an improvement over bagged trees by way of a random small tweak that decorrelates the trees. Each time a split in a tree is considered, a random sample of m<p predictors is chosen as split candidates from the full set of p predictors. \n",
    "\n",
    "The split is allowed to use only one of those m predictors, and this ultimately helps decorrelates the trees and generally leads to more accurate predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8564102564102564\n",
      "0.8033333333333333\n"
     ]
    }
   ],
   "source": [
    "#  random forest\n",
    "random_forest_model = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "\n",
    "print(cross_val_score(random_forest_model, X_train, y_train, cv=5).mean())\n",
    "print(cross_val_score(random_forest_model, X_test, y_test, cv=5).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests further improved the accuracy on the test set to 80%, and there is less overfitting now compared to bagging. The randomness introduced, also decreased the variance.\n",
    "\n",
    "Let's fine tune our hyperparameters to optimize the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9032258064516129\n",
      "{'max_depth': None, 'min_samples_split': 4, 'n_estimators': 10}\n",
      "0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "# Grid Search over n estimators, max samples\n",
    "params = {\n",
    "    'n_estimators': [5, 10, 15], \n",
    "    'max_depth': [None, 1, 2], \n",
    "    'min_samples_split': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# instantiate \n",
    "rf_grid_search = GridSearchCV(random_forest_model, param_grid=params, cv=5)\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# up to 90% on train, increased with more trees but not too many\n",
    "# but doesn't really matter as larger number of trees do not overfit as you are averaging\n",
    "# 86% accuracy on test!\n",
    "print(rf_grid_search.best_score_)\n",
    "print(rf_grid_search.best_params_)\n",
    "print(rf_grid_search.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Boosting \n",
    "Let's introduce another ensemble method. \n",
    "\n",
    "With boosting methods, trees are grown sequentially. Each tree is grown using information from previously grown trees. Boosting does not involve bootstrap sampling; instead each tree is fit on a modified version of the original data set. Similarly, the final prediction is constructed by a weighted vote: Weights for each base model depend on their training errors or misclassification rates.\n",
    "\n",
    "This method focuses on reduce bias by taking weak learners to start, and the algorithm is penalize wrong predictions in an iterative nature. Note, the number of trees is important here, as boosting can overfit, unlike in bagging and random forests. We can use cross validation to choose `n_estimators`. Boosting focuses on reducing bias, but can also reduce variance.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CatBoost  🐱"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do cats like chocolate? I don't know. Let's see if this boosting model can really purr, by implementing Cat Boost. \n",
    "\n",
    "[CatBoost](https://github.com/catboost/catboost) is a flavour (are you sick of my food puns yet), of boosting. It is a fast, scalable, high performance gradient boosting on decision trees library, used for ranking, classification, regression and other machine learning tasks.\n",
    "\n",
    "This is a pretty small data set, so we won't really see it shine like with large data sets, but it does come with some neat graphics for model evaluation metrics, which I did want to highlight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "cat_model = cb.CatBoostClassifier(\n",
    "    iterations=100, \n",
    "    early_stopping_rounds=10, # stop after 10 rounds if no improvement\n",
    "    custom_loss=['AUC', 'Accuracy'], # captures logloss by default, also capture auc and accuracy\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "# fit\n",
    "cat_model.fit(X_train, y_train, eval_set=(X_test, y_test),verbose=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical data\n",
    "# indices 0 to 7 \n",
    "categorical_features_indices = list(range(0, 8))\n",
    "\n",
    "cv_params = {'early_stopping_rounds': 10,\n",
    " 'random_state': 42,\n",
    " 'custom_loss': ['AUC', 'Accuracy'],\n",
    " 'loss_function': 'Logloss',\n",
    " 'iterations': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_data = cv(\n",
    "    Pool(X, y, cat_features=categorical_features_indices),\n",
    "    cv_params,\n",
    "    fold_count=5,\n",
    "    verbose=False)\n",
    "#    plot=True\n",
    "# 55 iterations for it to stabilize, 5 folds cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/catboost.png\" alt=\"catboost\" class=\"img-responsive\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation Logloss score, 0.3301±0.1217 on step 45\n"
     ]
    }
   ],
   "source": [
    "best_value = np.min(cv_data['test-Logloss-mean'])\n",
    "best_iter = cv_data['test-Logloss-mean'].idxmin()\n",
    "\n",
    "print('Best validation Logloss score, {:.4f}±{:.4f} on step {}'.format(\n",
    "    best_value,\n",
    "    cv_data['test-Logloss-std'][best_iter],\n",
    "    best_iter)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy score, 0.8779 on step 45\n"
     ]
    }
   ],
   "source": [
    "print('Validation accuracy score, {:.4f} on step {}'.format(\n",
    "    cv_data[cv_data[\"iterations\"]==45][\"test-Accuracy-mean\"].to_numpy()[0],\n",
    "    best_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside: By default, CatBoost optimizes for minimizing logloss, and with cross validation we select the model at 45 iterations. Basically, logloss increases as the predicted probability diverges from the actual label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"table\">\n",
    "<thead class=\"table-striped\">\n",
    "<tr>\n",
    "<th>Test scores</th>\n",
    "<th>Naive</th>\n",
    "<th>Vanilla Decision Tree</th>\n",
    "<th>Bagging</th>\n",
    "<th>Random Forest</th>    \n",
    "<th>CatBoost</th>\n",
    "</tr>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>Accuracy</td>\n",
    "<td>55.4%</td>\n",
    "<td>73.7%</td>\n",
    "<td>73.7%</td>\n",
    "<td>85.7%</td>\n",
    "<td>87.8%</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a caveat, with ensemble methods it is not always apparent which variables are most important to the procedure. Generally, boosting and bagging methods improves prediction accuracy at the expense of interpretability. Luckily, CatBoost has a`feature_importances` method to understand which feature made the greatest contribution to the final result. \n",
    "\n",
    "This shows that features `fruity` and `pricepercent` had the biggest influence on classifying if something was a chocolate or a candy. The same as our vanilla tree print out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fruity', 62.812208418548465),\n",
       " ('pricepercent', 21.388700907444946),\n",
       " ('pluribus', 4.915296243219509),\n",
       " ('sugarpercent', 3.809671603132506),\n",
       " ('caramel', 2.8654253284742484),\n",
       " ('nougat', 1.620219841699855),\n",
       " ('bar', 1.4484940632542251),\n",
       " ('hard', 1.0595256574622567),\n",
       " ('peanutyalmondy', 0.06755089925898686),\n",
       " ('crispedricewafer', 0.012907037505001707)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model.get_feature_importance(prettified=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Bonus: Unsupervised learning\n",
    "\n",
    "For a taste of what's to come in future posts, let's apply unsupervised learning to a problem to identify targets labels, y. No labels are given to the learning algorithm; it's left to find structure in its input. Unsupervised learning can be a goal in itself (discovering hidden patterns in data), or a means towards an end (feature learning). This is the latter application.\n",
    "\n",
    "\n",
    "Suppose you're a manager at Cadbury, and you want to create a new confectionery product for the masses. However, all you know is certain attributes of your snacks, and want to identify if there structure in your inventory. If there are patterns, then you might be able to create a new product with attributes that people will enjoy!\n",
    "\n",
    "---\n",
    "\n",
    "#### Life is like a 'cluster' of chocolates - Forrest Gump\n",
    "\n",
    "<img src=\"images/gump.png\" alt=\"gump\" class=\"img-responsive\">\n",
    "\n",
    "Okay, let's pretend we only have X. Our previous supervised learning model wouldn't be able to learn, and predict if something was chocolate or candy.\n",
    "\n",
    "How might we cluster these snacks into different categories? \n",
    "\n",
    "We can use K-means clustering to solve this, it's one of the most common methods. Again, we are NOT classifying explicitly, but rather exploring if there are common characteristics in k groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe table table-responsive table-striped table-bordered\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruity</th>\n",
       "      <th>caramel</th>\n",
       "      <th>peanutyalmondy</th>\n",
       "      <th>nougat</th>\n",
       "      <th>crispedricewafer</th>\n",
       "      <th>hard</th>\n",
       "      <th>bar</th>\n",
       "      <th>pluribus</th>\n",
       "      <th>sugarpercent</th>\n",
       "      <th>pricepercent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.loc[:, 'fruity':'pricepercent']\n",
    "HTML(X.sample().to_html(classes=\"table table-responsive table-striped table-bordered\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's look at the ground truth. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe table table-responsive table-striped table-bordered\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>competitorname</th>\n",
       "      <th>chocolate</th>\n",
       "      <th>fruity</th>\n",
       "      <th>caramel</th>\n",
       "      <th>peanutyalmondy</th>\n",
       "      <th>nougat</th>\n",
       "      <th>crispedricewafer</th>\n",
       "      <th>hard</th>\n",
       "      <th>bar</th>\n",
       "      <th>pluribus</th>\n",
       "      <th>sugarpercent</th>\n",
       "      <th>pricepercent</th>\n",
       "      <th>emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reeses Peanut Butter cup</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.651</td>\n",
       "      <td>🍫</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reeses Miniatures</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.279</td>\n",
       "      <td>🍫</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Twix</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.906</td>\n",
       "      <td>🍫</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kit Kat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.511</td>\n",
       "      <td>🍫</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Snickers</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.651</td>\n",
       "      <td>🍫</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emoji'] = [{1: '🍫', 0: '🍬'}[snack] for snack in df['chocolate']]\n",
    "HTML(df.head().to_html(classes=\"table table-responsive table-striped table-bordered\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = (alt.Chart(df, title='Ground Truth').mark_text(filled=True).encode(\n",
    "    x=alt.X('sugarpercent', axis=alt.Axis(title='sugar percentile', values = [0,0.2,0.4,0.6,0.8,1])),\n",
    "    y=alt.X('pricepercent', axis=alt.Axis(title='price percentile', values = [0,0.2,0.4,0.6,0.8,1])),\n",
    "    text='emoji'))#.save('../content/images/ground_truth.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/ground_truth.svg\" alt=\"ground_truth\" class=\"img-responsive\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it's not a very strong cluster, you can see that chocolates (black) tend to cost more relative to candies (red). The spread of the sugar amount varies, you have very sweet and less sweet snacks.\n",
    "\n",
    "Let's use k-means clustering, with k=2 clusters to see if we can categorize these snacks into two groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate\n",
    "kmeans_model = KMeans(n_clusters=2,random_state=42)\n",
    "\n",
    "# fit on X, don't need train and test as there's no 'accuracy' to measure\n",
    "# there is inertia, and silhouette, for comparing clustering methods, out of scope for this post\n",
    "kmeans_model.fit(X)\n",
    "\n",
    "# predict labels, group everything into 1 or 0\n",
    "kmeans_model.labels_;\n",
    "\n",
    "# add the learned cluster labels back to df\n",
    "df[\"cluster_label\"] = kmeans_model.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, each snack has a label of 1 or 0. From these 10 dimensions (fruity, caramel ... price percentile), the model was able to group these into two clusters that are the most similar to each other, by minimizing the within-cluster sum of squares.\n",
    "\n",
    "Since labels are arbitrary when clustering, we can rename the cluster labels to chocolate and candy emojis so we can compare to ground truth (since we have it, generally we wouldn't)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe table table-responsive table-striped table-bordered\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>competitorname</th>\n",
       "      <th>chocolate</th>\n",
       "      <th>fruity</th>\n",
       "      <th>caramel</th>\n",
       "      <th>peanutyalmondy</th>\n",
       "      <th>nougat</th>\n",
       "      <th>crispedricewafer</th>\n",
       "      <th>hard</th>\n",
       "      <th>bar</th>\n",
       "      <th>pluribus</th>\n",
       "      <th>sugarpercent</th>\n",
       "      <th>pricepercent</th>\n",
       "      <th>emoji</th>\n",
       "      <th>cluster_label</th>\n",
       "      <th>kmeans_emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reeses Peanut Butter cup</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.651</td>\n",
       "      <td>🍫</td>\n",
       "      <td>1</td>\n",
       "      <td>🍫</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reeses Miniatures</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.279</td>\n",
       "      <td>🍫</td>\n",
       "      <td>1</td>\n",
       "      <td>🍫</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Twix</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.906</td>\n",
       "      <td>🍫</td>\n",
       "      <td>1</td>\n",
       "      <td>🍫</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kit Kat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.511</td>\n",
       "      <td>🍫</td>\n",
       "      <td>1</td>\n",
       "      <td>🍫</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Snickers</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.651</td>\n",
       "      <td>🍫</td>\n",
       "      <td>1</td>\n",
       "      <td>🍫</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"kmeans_emoji\"] = df['cluster_label'].map({1: \"🍫\" , 0: \"🍬\"})\n",
    "HTML(df.head().to_html(classes=\"table table-responsive table-striped table-bordered\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8072289156626506"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df[\"emoji\"],df[\"kmeans_emoji\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By grouping observations into two sets, one group looks like chocolate, and the other group looks like candy, when compared on the two dimensions of price and sugar percentile.\n",
    "\n",
    "67 out of 83 observations were classified correctly. Hey, that's pretty good! \n",
    "\n",
    "Now, let's plot this with the centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48074999, 0.38033928],\n",
       "       [0.50892592, 0.66403704]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_model.cluster_centers_ #2 clusters in 11 dimensions\n",
    "# take the elements for sugar and price\n",
    "# index 9 and 10\n",
    "kmeans_model.cluster_centers_[:,8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot centroids\n",
    "centroids = pd.DataFrame(kmeans_model.cluster_centers_[:,8:])\n",
    "centroids.columns = [\"sugarpercent\",\"pricepercent\"]\n",
    "centroids['kmeans_emoji'] = pd.DataFrame({\"kmeans_emoji\": [\"🍬\",\"🍫\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = (alt.Chart(df, title='K-means, with 2 Clusters').mark_text(filled=True).encode(\n",
    "    x=alt.X('sugarpercent', axis=alt.Axis(title='sugar percentile', values = [0,0.2,0.4,0.6,0.8,1])),\n",
    "    y=alt.X('pricepercent', axis=alt.Axis(title='price percentile', values = [0,0.2,0.4,0.6,0.8,1])),\n",
    "    text='kmeans_emoji'))\n",
    "\n",
    "centroid_plot = (alt.Chart(centroids).mark_text(filled=True, size=40).encode(\n",
    "    x=alt.X('sugarpercent', axis=alt.Axis(title='sugar percentile', values = [0,0.2,0.4,0.6,0.8,1])),\n",
    "    y=alt.X('pricepercent', axis=alt.Axis(title='price percentile', values = [0,0.2,0.4,0.6,0.8,1])),\n",
    "    text='kmeans_emoji'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "(alt.hconcat(kmeans + centroid_plot, ground_truth)\n",
    " .configure_axis(gridOpacity=0.25)).save('../content/images/compare.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/compare.svg\" alt=\"compare\" class=\"img-responsive\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: For the k-means graph on the left, the 2 clusters centroids (calculated from multi-dimensional space) are indicated by the oversized chocolate and candy emojis. They are computed as the mean of the observations assigned to each cluster."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
