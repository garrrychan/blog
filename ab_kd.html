<!DOCTYPE html>
<!--[if lt IE 7 ]><html class="ie ie6" lang="en"> <![endif]-->
<!--[if IE 7 ]><html class="ie ie7" lang="en"> <![endif]-->
<!--[if IE 8 ]><html class="ie ie8" lang="en"> <![endif]-->
<!--[if (gte IE 9)|!(IE)]><!--><html lang="en"> <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="author" content="Garry Chan">
  <meta name="description" content="Posts by Garry Chan">
  <!-- mathjax for $ -->
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        processEscapes: true
      }
    });
  </script>
  <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>
  <title>
    Garry's Blog
&ndash; Are the Warriors better without Kevin Durant?  </title>

    <link rel="canonical" href="https://garrrychan.github.io/blog/ab_kd.html">

  <link href="//fonts.googleapis.com/css?family=Open+Sans:600,800" rel="stylesheet" type="text/css">
  <!------>
  <link rel="shortcut icon" href="https://garrrychan.github.io/blog/theme/images/gary_snail.png">  <link rel="stylesheet" type="text/css" href="https://garrrychan.github.io/blog/theme/css/bootstrap.css">
  <link rel="stylesheet" type="text/css" href="https://garrrychan.github.io/blog/theme/css/all.css">
  <link rel="stylesheet" type="text/css" href="https://garrrychan.github.io/blog/theme/css/pygments-monokai.css">
</head>
<body>
  <div class="container">
    <div class="four columns sidebar">
<nav>
  <a href="https://garrrychan.github.io/blog/">
    <img src="https://garrrychan.github.io/blog/theme/images/logo2.jpg" id="gravatar" alt="photo"/>
  </a>
  <h2><a href="https://garrrychan.github.io/blog/">Garry Chan</a></h2>

  <div id="bio">
    <p>I write about data science, and occasionally sports.</p>
    <p>Completed a full time data science program.</p>
    <p>Experience as a tech consultant, with a Bachelors in Mathematics from UWaterloo.</p>
  </div>

  <div id="social">
    <div>
      <i class="fas fa-map-marker-alt fa-2x" style="color:#ddd">
      <span class="location_icon"> <font color=#000> Toronto, Canada </font></span> </i>
      </div>
    <br>
    <a title="Garry on LinkedIn" href="https://www.linkedin.com/in/garrrychan">
      <!--- icons from font awesome are really just fonts fa-2x the size--->
    <i class="fab fa-linkedin fa-2x"></i></a>

    &nbsp &nbsp;
    <a title="Garry on Github" href="https://github.com/garrrychan">
    <i class="fab fa-github fa-2x"></i></a>

    &nbsp &nbsp;
    <a title="Garry's Email" href="mailto: g33chan@uwaterloo.ca">
    <i class="fas fa-envelope-square fa-2x"></i>
    </a>
  </div>
</nav>    </div>

    <div class="eleven columns content">
  <p class="meta">
    10 June 2019
    <a href="https://garrrychan.github.io/blog">
      <!--- home icon--->
      <i class="home fa fa-home fa-2x"></i>
    </a>
  </p>

  <h1 class="title"><a href="https://garrrychan.github.io/blog/ab_kd.html">Are the Warriors better without Kevin Durant?</a></h1>

  <div class="article_text" id="post">
    <p>In the media, there have been debates about whether or not the Golden State Warriors (GSW) are better without Kevin Durant (KD). From the eye-test, it's laughable to even suggest this, as he's one of the top 3 players in the league (Lebron, KD, Kawhi). Nonetheless, people argue that ball movement is better without him, and therefore make the GSW more lethal.</p>
<p>But, just because the Warriors won a title without KD, that does not mean they don't need him more than ever. At the time of writing, the Toronto Raptors lead 3-1 in the Finals! #WeTheNorth ü¶ñüçÅ</p>
<p>Using Bayesian estimation, we can A/B test this hypothesis, by comparing two treatment groups: games played with KD vs. without KD.</p>
<p>Bayesian statistics are an excellent tool to reach for when sample sizes are small, as we can introduce explicit assumptions into the model, when there aren't thousands of observations. </p>
<hr>
<h3>Primer on Bayesian Statistics</h3>
<p><img src="images/dists.png" class="img-responsive"></p>
<p>$$P\left(model\;|\;data\right) = \frac{P\left(data\;|\;model\right)}{P(data)}\; P\left(model\right)$$</p>
<p>$$ \text{prior} = P\left(model\right) $$</p>
<blockquote>
<p>The <strong>prior</strong> is our belief in the model given no additional information. In our example, this is the mean win % with KD playing.
<br></p>
</blockquote>
<p>$$ \text{likelihood} = P\left(data\;|\;model\right) $$</p>
<blockquote>
<p>The <strong>likelihood</strong> is the probability of the data we observed occurring given the model.
<br></p>
</blockquote>
<p>$$ \text{marginal probability of data} = P(data) $$</p>
<blockquote>
<p>The <strong>marginal probability</strong> of the data is the probability that our data are observed regardless of what model we choose or believe in. 
<br></p>
</blockquote>
<p>$$ \text{posterior} = P\left(model\;|\;data\right) $$</p>
<blockquote>
<p>The <strong>posterior</strong> is our <em>updated</em> belief in the model given the new data we have observed. Bayesian statistics are all about updating a prior belief we have about the world with new data, so we're transforming our <em>prior</em> belief into this new <em>posterior</em> belief about the world. <br><br> In this example, this is the GSW mean winning % with KD playing, given the game logs from the past three seasons.</p>
</blockquote>
<p><br> Note, a Bayesian approach is different from a Frequentist's. Rather than only testing whether two groups are different, we instead pursue an estimate of <em>how</em> different they are, from the posterior distribution.</p>
<h4>Objective</h4>
<p>To calculate the distribution of the posterior probability of GSW mean winning % with KD and without KD.
Moreover, we can calculate the <em>delta</em> between both probabilities to determine if the mean is statistically different from zero (i.e. no difference with or without him).</p>
<hr>
<h4>Observed Data</h4>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="kn">as</span> <span class="nn">stats</span>
<span class="kn">import</span> <span class="nn">pymc3</span> <span class="kn">as</span> <span class="nn">pm</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;fivethirtyeight&#39;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">IPython.core.pylabtools</span> <span class="kn">import</span> <span class="n">figsize</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">FutureWarning</span><span class="p">)</span>
</pre></div>


<p>As the competition is much higher in the playoffs, let's analyze playoff vs. regular Season data separately. We can run one test on the regular season, and one test for the playoffs.  </p>
<p>Data is from <a href="https://www.basketball-reference.com/">Basketball Reference</a>.</p>
<hr>
<h3>Regular Season</h3>
<table class="table-responsive table-striped  table-bordered">
 <thead>
    <tr>
      <th scope="col">Regular Season</th>
      <th scope="col">With Kevin Durant</th>
      <th scope="col">No Kevin Durant</th>
      <th scope="col">Notes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2019</td>
      <td>0.69 <br> {'W': 54, 'L': 24} </td>
      <td>0.75 <br> {'W': 3, 'L': 1} </td>
      <td>Record is better when KD is out, but small sample size.</td>
    </tr>
    <tr>
      <td>2018</td>
      <td>0.72 <br> {'W': 49, 'L': 19} </td>
      <td>0.64 <br> {'W': 9, 'L': 5} </td>
      <td>Record is better when KD plays</td>
    </tr>
    <tr>
      <td>2017</td>
      <td>0.82 <br> {'W': 51, 'L': 11} </td>
      <td>0.80 <br> {'W': 16, 'L': 4} </td>
      <td>Record is better when KD plays</td>
    </tr>
    <tr>
      <td>Total (3 seasons)</td>
      <td>0.740 <br> {'W': 154, 'L': 54} </td>
      <td>0.737 <br> {'W': 28, 'L': 10} </td>
      <td>Record is better when KD plays</td>
    </tr>
  </tbody>
</table>

<p>Over the last three seasons with the Warriors, KD has missed 38 games regular season games, and played in 208.</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">occurrences</span><span class="p">(</span><span class="n">year</span><span class="p">,</span> <span class="n">kd</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;occurences(2019, kd=True)</span>
<span class="sd">    By default, kd=True means with KD healthy&#39;&#39;&#39;</span>
    <span class="c1"># clean data</span>
    <span class="c1"># regular season</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;./data/ab/{year}.txt&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
    <span class="n">new_columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Rk&#39;</span><span class="p">,</span> <span class="s1">&#39;G&#39;</span><span class="p">,</span> <span class="s1">&#39;Date&#39;</span><span class="p">,</span> <span class="s1">&#39;Age&#39;</span><span class="p">,</span> <span class="s1">&#39;Tm&#39;</span><span class="p">,</span> <span class="s1">&#39;Away&#39;</span><span class="p">,</span> <span class="s1">&#39;Opp&#39;</span><span class="p">,</span> <span class="s1">&#39;Result&#39;</span><span class="p">,</span> <span class="s1">&#39;GS&#39;</span><span class="p">,</span>
       <span class="s1">&#39;MP&#39;</span><span class="p">,</span> <span class="s1">&#39;FG&#39;</span><span class="p">,</span> <span class="s1">&#39;FGA&#39;</span><span class="p">,</span> <span class="s1">&#39;FG%&#39;</span><span class="p">,</span> <span class="s1">&#39;3P&#39;</span><span class="p">,</span> <span class="s1">&#39;3PA&#39;</span><span class="p">,</span> <span class="s1">&#39;3P%&#39;</span><span class="p">,</span> <span class="s1">&#39;FT&#39;</span><span class="p">,</span> <span class="s1">&#39;FTA&#39;</span><span class="p">,</span> <span class="s1">&#39;FT%&#39;</span><span class="p">,</span> <span class="s1">&#39;ORB&#39;</span><span class="p">,</span>
       <span class="s1">&#39;DRB&#39;</span><span class="p">,</span> <span class="s1">&#39;TRB&#39;</span><span class="p">,</span> <span class="s1">&#39;AST&#39;</span><span class="p">,</span> <span class="s1">&#39;STL&#39;</span><span class="p">,</span> <span class="s1">&#39;BLK&#39;</span><span class="p">,</span> <span class="s1">&#39;TOV&#39;</span><span class="p">,</span> <span class="s1">&#39;PF&#39;</span><span class="p">,</span> <span class="s1">&#39;PTS&#39;</span><span class="p">,</span> <span class="s1">&#39;GmSc&#39;</span><span class="p">,</span> <span class="s1">&#39;+/-&#39;</span><span class="p">]</span>
    <span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="o">=</span><span class="n">new_columns</span>
    <span class="c1"># replace did not dress with inactive</span>
    <span class="n">data</span><span class="o">.</span><span class="n">GS</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">GS</span> <span class="o">==</span> <span class="s1">&#39;Did Not Dress&#39;</span><span class="p">,</span><span class="s1">&#39;Inactive&#39;</span><span class="p">,</span><span class="n">data</span><span class="o">.</span><span class="n">GS</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">kd</span> <span class="o">==</span> <span class="bp">False</span><span class="p">:</span>
        <span class="n">game_logs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">GS</span><span class="o">==</span><span class="s1">&#39;Inactive&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">Result</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">game_logs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">GS</span><span class="o">!=</span><span class="s1">&#39;Inactive&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">Result</span><span class="p">)</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[</span><span class="n">game</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">game</span> <span class="ow">in</span> <span class="n">game_logs</span><span class="p">]</span>
    <span class="n">occurrences</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="k">if</span> <span class="n">result</span> <span class="o">==</span> <span class="s1">&#39;W&#39;</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">occurrences</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">regular_season_with_kd</span> <span class="o">=</span> <span class="n">occurrences</span><span class="p">(</span><span class="mi">2019</span><span class="p">,</span> <span class="n">kd</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span><span class="o">+</span><span class="n">occurrences</span><span class="p">(</span><span class="mi">2018</span><span class="p">,</span> <span class="n">kd</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span><span class="o">+</span><span class="n">occurrences</span><span class="p">(</span><span class="mi">2017</span><span class="p">,</span> <span class="n">kd</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">regular_season_no_kd</span> <span class="o">=</span> <span class="n">occurrences</span><span class="p">(</span><span class="mi">2019</span><span class="p">,</span> <span class="n">kd</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span><span class="o">+</span><span class="n">occurrences</span><span class="p">(</span><span class="mi">2018</span><span class="p">,</span> <span class="n">kd</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span><span class="o">+</span><span class="n">occurrences</span><span class="p">(</span><span class="mi">2017</span><span class="p">,</span> <span class="n">kd</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Observed win % when Kevin Durant plays: {round(np.mean(regular_season_with_kd),4)}&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Observed win % when Kevin Durant does not play: {round(np.mean(regular_season_no_kd),4)}&#39;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>Observed win % when Kevin Durant plays: 0.7404
Observed win % when Kevin Durant does not play: 0.7368
</pre></div>


<ul>
<li>
<p>Note, we do not know the true win %, only the observed win %. We infer the true quantity from the observed data.</p>
</li>
<li>
<p>Notice the unequal sample sizes (208 vs. 38), but this is not problem in Bayesian analysis. We will see the uncertainty of the smaller sample size captured in the posterior distribution. </p>
</li>
</ul>
<hr>
<h4>Bayesian Tests with MCMC</h4>
<ul>
<li>
<p>Markov Chain Monte Carlo (MCMC) is a method to find the posterior distribution of our parameter of interest.</p>
<blockquote>
<p>This type of algorithm generates Monte Carlo simulations in a way that relies on the Markov property, then accepts these simulations at a certain rate to get the posterior distribution.</p>
</blockquote>
</li>
<li>
<p>We will use <a href="https://docs.pymc.io/">PyMC3</a>, a probabilistic library for Python to generate MC simulations.</p>
</li>
<li>
<p>Before seeing any of the data, my prior is that GSW will win between 50% - 90% of their games, because they are an above average basketball team, and no team has ever won more than 72 games.</p>
</li>
</ul>
<div class="highlight"><pre><span></span><span class="c1"># Instantiate</span>
<span class="n">observations_A</span> <span class="o">=</span> <span class="n">regular_season_with_kd</span>
<span class="n">observations_B</span> <span class="o">=</span> <span class="n">regular_season_no_kd</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model</span><span class="p">:</span>
    <span class="c1"># Assume Uniform priors for p_A and p_B    </span>
    <span class="n">p_A</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="s2">&quot;p_A&quot;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="o">.</span><span class="mi">9</span><span class="p">)</span>
    <span class="n">p_B</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="s2">&quot;p_B&quot;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="o">.</span><span class="mi">9</span><span class="p">)</span>

    <span class="c1"># Define the deterministic delta function. This is our unknown of interest.</span>
    <span class="c1"># Delta is deterministic, no uncertainty beyond p_A and p_B</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s2">&quot;delta&quot;</span><span class="p">,</span> <span class="n">p_A</span> <span class="o">-</span> <span class="n">p_B</span><span class="p">)</span>

    <span class="c1"># We have two observation datasets: A, B</span>
    <span class="c1"># Posterior distribution is Bernoulli</span>
    <span class="n">obs_A</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="s2">&quot;obs_A&quot;</span><span class="p">,</span> <span class="n">p_A</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">observations_A</span><span class="p">)</span>
    <span class="n">obs_B</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="s2">&quot;obs_B&quot;</span><span class="p">,</span> <span class="n">p_B</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">observations_B</span><span class="p">)</span>

    <span class="c1"># Draw samples from the posterior distribution</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">20000</span><span class="p">)</span>
    <span class="n">burned_trace</span><span class="o">=</span><span class="n">trace</span><span class="p">[</span><span class="mi">1000</span><span class="p">:]</span>
</pre></div>


<div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (2 chains in 2 jobs)
NUTS: [p_B, p_A]
Sampling 2 chains: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41000/41000 [00:21&lt;00:00, 1899.05draws/s]
</pre></div>


<ul>
<li>Using PyMC3, we generated a trace, or chain of values from the posterior distribution </li>
<li>Generated 20,000 samples from the posterior distribution (20,000 samples / chain / core)</li>
</ul>
<p>Because this algorithm needs to converge, we set a number of tuning steps (1,000) to occur first and where the algorithm should "start exploring." It's good to see the Markov Chains overlap, which suggests convergence.</p>
<p><img src="images/trace.svg" class="img-responsive"></p>
<div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">burned_trace</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)[[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="s1">&#39;sd&#39;</span><span class="p">,</span> <span class="s1">&#39;hpd_2.5&#39;</span><span class="p">,</span> <span class="s1">&#39;hpd_97.5&#39;</span><span class="p">]]</span>
<span class="n">HTML</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">to_html</span><span class="p">(</span><span class="n">classes</span><span class="o">=</span><span class="s2">&quot;table table-responsive table-striped table-bordered&quot;</span><span class="p">))</span>
</pre></div>


<table border="1" class="dataframe table table-responsive table-striped table-bordered">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>hpd_2.5</th>
      <th>hpd_97.5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>p_A</th>
      <td>0.74</td>
      <td>0.03</td>
      <td>0.68</td>
      <td>0.80</td>
    </tr>
    <tr>
      <th>p_B</th>
      <td>0.73</td>
      <td>0.07</td>
      <td>0.59</td>
      <td>0.85</td>
    </tr>
    <tr>
      <th>delta</th>
      <td>0.01</td>
      <td>0.07</td>
      <td>-0.13</td>
      <td>0.16</td>
    </tr>
  </tbody>
</table>

<ul>
<li>Unlike with confidence intervals (frequentist), there is a measure of probability with the credible interval.</li>
<li>There is a 95% probability that the true win rate with KD is in the interval (0.68, 0.79).</li>
<li>There is a 95% probability that the true win rate with no KD is in the interval (0.59, 0.85).</li>
</ul>
<p><img src="images/reg_season.svg" class="img-responsive"></p>
<p>Note, the 2.5% and 97.5% markers indicate the quantiles for the credible interval, similar to the confidence interval in frequentist statistics.</p>
<hr>
<h4>Results</h4>
<ul>
<li>
<p>In the third graph, the posterior win rate is 1.2% higher when KD plays in the regular season.</p>
</li>
<li>
<p>Observe that because have less data for when KD is out, our posterior distribution of  $ùëù_ùêµ$ is wider, implying we are less certain about the true value of $ùëù_ùêµ$ than we are of $ùëù_ùê¥$. The 95% credible interval is much wider for $ùëù_ùêµ$, as there is a smaller sample size, for when KD did not play. We are less certain that the GSW wins 73% of the time without KD.</p>
</li>
<li>
<p>The difference in sample sizes ($N_B$ &lt; $N_A$) naturally fits into Bayesian analysis, whereas you need the same populations for frequentist approach!</p>
</li>
</ul>
<div class="highlight"><pre><span></span><span class="c1"># Count the number of samples less than 0, i.e. the area under the curve</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Probability that GSW is worse with Kevin Durant in the regular season: </span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> \
    <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">delta_samples</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Probability that GSW is better with Kevin Durant in the regular season: </span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> \
    <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">delta_samples</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">))</span>
</pre></div>


<div class="highlight"><pre><span></span>Probability that GSW is worse with Kevin Durant in the regular season: 0.45
Probability that GSW is better with Kevin Durant in the regular season: 0.55
</pre></div>


<p>The probabilities are pretty close, so we can chalk this up to the Warriors having a experienced supporting cast. </p>
<p>There is significant overlap between the distribution pf posterior $p_A$ and posterior of $p_B$, so one is not better than the other with high probability. The majority of the distribution of delta is around 0, so there is no statistically difference between the groups in the regular season.</p>
<p>Ideally, we should perform more trials when KD is injured (as each data point for scenario B contributes more inferential power than each additional point for scenario A). One could do a similar analysis for when he played on the Oklahoma City Thunder.</p>
<hr>
<h3>Playoffs</h3>
<h4>Do superstars shine when the stakes are highest?</h4>
<table class="table-responsive table-striped  table-bordered">
 <thead>
    <tr>
      <th scope="col">Playoffs</th>
      <th scope="col">With Kevin Durant</th>
      <th scope="col">No Kevin Durant</th>
      <th scope="col">Notes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>2019</td>
      <td>0.64 <br> {'W': 7, 'L': 4} </td>
      <td>0.66 <br> {'W': 6, 'L': 3} </td>
      <td>Record is marginally better when KD is out, but small sample size. Skewed by Portland series, which GSW won 4-0 with KD injured.</td>
    </tr>
    <tr>
      <td>2018</td>
      <td>0.76 <br> {'W': 16, 'L': 5} </td>
      <td>n/a <br> {'W': 0, 'L': 0} </td>
      <td>KD did not miss any games. Won Championship.</td>
    </tr>
    <tr>
      <td>2017</td>
      <td>0.82 <br> {'W': 14, 'L': 1} </td>
      <td>1 <br> {'W': 2, 'L': 0}. Small sample size. </td>
      <td>Won championship.</td>
    </tr>
      <td>Total (3 seasons)</td>
      <td>0.79 <br> {'W': 37, 'L': 10} </td>
      <td>0.73 <br> {'W': 8, 'L': 3} </td>
      <td>Record is better when KD plays</td>
  </tbody>
</table>

<div class="highlight"><pre><span></span><span class="n">playoffs_with_kd</span> <span class="o">=</span> <span class="n">occurrences</span><span class="p">(</span><span class="s1">&#39;2019_playoffs&#39;</span><span class="p">,</span> <span class="n">kd</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span><span class="o">+</span><span class="n">occurrences</span><span class="p">(</span><span class="s1">&#39;2018_playoffs&#39;</span><span class="p">,</span> <span class="n">kd</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span><span class="o">+</span><span class="n">occurrences</span><span class="p">(</span><span class="s1">&#39;2017_playoffs&#39;</span><span class="p">,</span> <span class="n">kd</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">playoffs_no_kd</span> <span class="o">=</span> <span class="n">occurrences</span><span class="p">(</span><span class="s1">&#39;2019_playoffs&#39;</span><span class="p">,</span> <span class="n">kd</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span><span class="o">+</span><span class="n">occurrences</span><span class="p">(</span><span class="s1">&#39;2018_playoffs&#39;</span><span class="p">,</span> <span class="n">kd</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span><span class="o">+</span><span class="n">occurrences</span><span class="p">(</span><span class="s1">&#39;2017_playoffs&#39;</span><span class="p">,</span> <span class="n">kd</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Observed win % when Kevin Durant plays: {round(np.mean(playoffs_with_kd),2)}&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Observed win % when Kevin Durant does not play: {round(np.mean(playoffs_no_kd),2)}&#39;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span>Observed win % when Kevin Durant plays: 0.79
Observed win % when Kevin Durant does not play: 0.73
</pre></div>


<p>Over the last three playoff runs with the Warriors, KD has missed 11, and played in 47. By combining results from the past three seasons, we obtain a larger test group, which allows us to observe a real change vs. looking at the statistics for a single year. The difference is more pronounced across three seasons. </p>
<p>Let's simulate to see investigate if GSW has a higher win % with KD in the playoffs. </p>
<div class="highlight"><pre><span></span><span class="n">playoff_obs_A</span> <span class="o">=</span> <span class="n">playoffs_with_kd</span>
<span class="n">playoff_obs_B</span> <span class="o">=</span> <span class="n">playoffs_no_kd</span>

<span class="k">with</span> <span class="n">pm</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">playoff_model</span><span class="p">:</span>
    <span class="n">playoff_p_A</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="s2">&quot;playoff_p_A&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">playoff_p_B</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Uniform</span><span class="p">(</span><span class="s2">&quot;playoff_p_B&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">playoff_delta</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Deterministic</span><span class="p">(</span><span class="s2">&quot;playoff_delta&quot;</span><span class="p">,</span> <span class="n">playoff_p_A</span> <span class="o">-</span> <span class="n">playoff_p_B</span><span class="p">)</span>

    <span class="n">playoff_obs_A</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="s2">&quot;playoff_obs_A&quot;</span><span class="p">,</span> <span class="n">playoff_p_A</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">playoff_obs_A</span><span class="p">)</span>
    <span class="n">playoff_obs_B</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="s2">&quot;playoff_obs_B&quot;</span><span class="p">,</span> <span class="n">playoff_p_B</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">playoff_obs_B</span><span class="p">)</span>

    <span class="n">playoff_trace</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">20000</span><span class="p">)</span>
    <span class="n">playoff_burned_trace</span><span class="o">=</span><span class="n">playoff_trace</span><span class="p">[</span><span class="mi">1000</span><span class="p">:]</span>
</pre></div>


<div class="highlight"><pre><span></span>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (2 chains in 2 jobs)
NUTS: [playoff_p_B, playoff_p_A]
Sampling 2 chains: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41000/41000 [00:23&lt;00:00, 1709.99draws/s]
</pre></div>


<div class="highlight"><pre><span></span><span class="n">df2</span> <span class="o">=</span> <span class="n">pm</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">playoff_burned_trace</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)[[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="s1">&#39;sd&#39;</span><span class="p">,</span> <span class="s1">&#39;hpd_2.5&#39;</span><span class="p">,</span> <span class="s1">&#39;hpd_97.5&#39;</span><span class="p">]]</span>
<span class="n">HTML</span><span class="p">(</span><span class="n">df2</span><span class="o">.</span><span class="n">to_html</span><span class="p">(</span><span class="n">classes</span><span class="o">=</span><span class="s2">&quot;table table-responsive table-striped table-bordered&quot;</span><span class="p">))</span>
</pre></div>


<table border="1" class="dataframe table table-responsive table-striped table-bordered">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>hpd_2.5</th>
      <th>hpd_97.5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>playoff_p_A</th>
      <td>0.78</td>
      <td>0.06</td>
      <td>0.66</td>
      <td>0.88</td>
    </tr>
    <tr>
      <th>playoff_p_B</th>
      <td>0.69</td>
      <td>0.12</td>
      <td>0.46</td>
      <td>0.92</td>
    </tr>
    <tr>
      <th>playoff_delta</th>
      <td>0.08</td>
      <td>0.14</td>
      <td>-0.17</td>
      <td>0.36</td>
    </tr>
  </tbody>
</table>

<p><img src="images/playoffs.svg" class="img-responsive"></p>
<div class="highlight"><pre><span></span><span class="c1"># Count the number of samples less than 0, i.e. the area under the curve</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Probability that GSW is worse with Kevin Durant in the playoffs: </span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> \
    <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">playoff_delta_samples</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Probability that GSW is better with Kevin Durant in the playoffs: </span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> \
    <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">playoff_delta_samples</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">))</span>
</pre></div>


<div class="highlight"><pre><span></span>Probability that GSW is worse with Kevin Durant in the playoffs: 0.28
Probability that GSW is better with Kevin Durant in the playoffs: 0.72
</pre></div>


<hr>
<h4>Are the Warriors better without Kevin Durant?</h4>
<p>No.</p>
<p>We can see that while delta = 0 (i.e. no effect when KD plays) is in the credible interval at 95%, the majority of the distribution is above 0. This A/B test implies that the treatment group with KD, is likely better than the group without KD. In fact, the probability that GSW is better with Kevin Durant in the playoffs is 72%, a significant jump from 55% in the regular season! </p>
<p>Superstars make a difference in the playoffs. The regular season is where you make your name, but the postseason is where you make your fame. The delta is 8% higher with KD. That's the advantage you gain with a player of his caliber, as he can hit clutch shots when it matters most.</p>
<h4>References</h4>
<ul>
<li><a href="https://multithreaded.stitchfix.com/blog/2015/05/26/significant-sample/">Significant Samples</a></li>
<li><a href="https://multithreaded.stitchfix.com/blog/2015/02/12/may-bayes-theorem-be-with-you/">May Bayes Theorem Be With You</a></li>
</ul>
  </div>



      <div class="footer">
<div class="disclaimer">

    <p>
      ¬© Garry Chan 2019 &mdash; built with <a href="http://getpelican.com" target="_blank">Pelican</a>, built off of the theme <a href="https://github.com/swanson/lagom" target="_blank">Lagom</a>.
    </p>
  </div>      </div>
    </div>
  </div>

<!-- my kit for font awesome  -->
<script src="https://kit.fontawesome.com/54282dd713.js"></script>
</body>
</html>